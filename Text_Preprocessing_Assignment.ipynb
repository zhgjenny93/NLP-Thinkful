{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Preprocessing Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP4jRpA5MHXvT+teDR0f7a3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhgjenny93/NLP-Thinkful/blob/main/Text_Preprocessing_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2Xdu5XLjloB"
      },
      "source": [
        "In this assignment, you'll clean up the two datasets. You'll be using these datasets in the later checkpoints of this module, and cleaning them up here will help you save time when working with these datasets.\n",
        "\n",
        "The first dataset is a dialogue dataset called [Cornell Movie--Dialogs Corpus](http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html). This corpus includes conversations between the characters of more than 600 movies.\n",
        "\n",
        "The second dataset is the [Twitter US Airline Sentiment](https://www.kaggle.com/crowdflower/twitter-airline-sentiment) dataset from Kaggle. This dataset contains tweets from travelers about some airlines in February 2015. This dataset is usually used in sentiment analysis, but you'll use it for sentence generation later on.\n",
        "\n",
        "**Note:** Because the memory requirements of the datasets are relatively large, it's best to use Google Colaboratory for this assignment.\n",
        "\n",
        "Submit your solutions to the following tasks as a link to your Jupyter Notebook on GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVHhqyL8kAf3"
      },
      "source": [
        "1. Apply the data preprocessing techniques that you learned here to the Cornell Movie--Dialogs Corpus data. You'll use this dataset when developing a chatbot in an upcoming checkpoint. Access the dataset from the Thinkful database using the following credentials:\n",
        "\n",
        " ```\n",
        " postgres_user = 'dsbc_student'\n",
        " postgres_pw = '7*.8G9QH21'\n",
        " postgres_host = '142.93.121.174'\n",
        " postgres_port = '5432'\n",
        " postgres_db = 'cornell_movie_dialogs'\n",
        " ```\n",
        "The data is in the table called dialogs.\n",
        "\n",
        "2. Apply the data preprocessing techniques that you learned here to Twitter US Airline Sentiment data. You'll use this dataset when generating sentences in an upcoming checkpoint. You should access the dataset from the Thinkful database using the following credentials:\n",
        "\n",
        " ```\n",
        " postgres_user = 'dsbc_student'\n",
        " postgres_pw = '7*.8G9QH21'\n",
        " postgres_host = '142.93.121.174'\n",
        " postgres_port = '5432'\n",
        " postgres_db = 'twitter_sentiment'\n",
        " ```\n",
        "The data is in the table called twitter.\n",
        "\n",
        "**Note:** When parsing the data using spaCy, you may run into some memory issues, even in Google Colaboratory. If you're having memory issues, try parsing your text as follows:\n",
        "\n",
        "```\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "nlp.max_length = 20000000\n",
        "doc = nlp(the_dialogs_come_here)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szeL_VXBJ6cL"
      },
      "source": [
        "## Part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z21KDUMzjgko"
      },
      "source": [
        "from sqlalchemy import create_engine\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "yCV9sSIVmA6L",
        "outputId": "7691ae20-d542-4e7c-ae47-dab7fb9ae005"
      },
      "source": [
        "postgres_user = 'dsbc_student'\n",
        "postgres_pw = '7*.8G9QH21'\n",
        "postgres_host = '142.93.121.174'\n",
        "postgres_port = '5432'\n",
        "postgres_db = 'cornell_movie_dialogs'\n",
        "\n",
        "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
        "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
        "\n",
        "dialogs_df = pd.read_sql_query('select * from dialogs', con=engine)\n",
        "\n",
        "# no need for an open connection, as we're only doing a single query\n",
        "engine.dispose()\n",
        "\n",
        "dialogs_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>dialogs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Not the hacking and gagging and spitting part....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Okay... then how 'bout we try out some French ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Forget it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Cameron.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>The thing is, Cameron -- I'm at the mercy of a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Seems like she could get a date easy enough...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                            dialogs\n",
              "0      0  Can we make this quick?  Roxanne Korrine and A...\n",
              "1      1  Well, I thought we'd start with pronunciation,...\n",
              "2      2  Not the hacking and gagging and spitting part....\n",
              "3      3  Okay... then how 'bout we try out some French ...\n",
              "4      4  You're asking me out.  That's so cute. What's ...\n",
              "5      5                                         Forget it.\n",
              "6      6  No, no, it's my fault -- we didn't have a prop...\n",
              "7      7                                           Cameron.\n",
              "8      8  The thing is, Cameron -- I'm at the mercy of a...\n",
              "9      9     Seems like she could get a date easy enough..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9--hTgYhEQlG"
      },
      "source": [
        "# Remove new lines and other extra whitespace by creating str from df and splitting and rejoining\n",
        "\n",
        "dialogs_str = ' '.join(dialogs_df.dialogs)\n",
        "dialogs_str = ' '.join(dialogs_str.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cnx4fREEcBf",
        "outputId": "51b896b2-9c5f-4b6c-d793-ba656d51421b"
      },
      "source": [
        "print(dialogs_str[:300])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Can we make this quick? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad. Again. Well, I thought we'd start with pronunciation, if that's okay with you. Not the hacking and gagging and spitting part. Please. Okay... then how 'bout we try out some Fr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaKmuarXuf3E"
      },
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# below is necessary to avoid memory error of SpaCy\n",
        "nlp.max_length = 20000000\n",
        "\n",
        "# all the processing work is done here, may take a while\n",
        "dialogs_doc = nlp(dialogs_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7esddJT14lH",
        "outputId": "07cf04da-cfec-4f7d-b7c0-1ff1c3175396"
      },
      "source": [
        "print('The dialogs_doc object is a {} object'.format(type(dialogs_doc)))\n",
        "print('It is {} tokens long'.format(len(dialogs_doc)))\n",
        "print(\"The first three tokens are '{}'\".format(dialogs_doc[:3]))\n",
        "print(\"The type of each token is {}\".format(type(dialogs_doc[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dialogs_doc object is a <class 'spacy.tokens.doc.Doc'> object\n",
            "It is 4189028 tokens long\n",
            "The first three tokens are 'Can we make'\n",
            "The type of each token is <class 'spacy.tokens.token.Token'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OzBjnkb7EIU"
      },
      "source": [
        "# Removing stopwords\n",
        "dialogs_without_stopwords = [token for token in dialogs_doc if not token.is_stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c3Ls3Lr7fpF"
      },
      "source": [
        "# print(dialogs_without_stopwords[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4gkWGWG7sY3",
        "outputId": "bf0415e9-de93-4af1-b020-a3113c3d0449"
      },
      "source": [
        "# Utility function to calculate how frequently words appear in the text\n",
        "def word_frequencies(text):\n",
        "  # Build a list of words\n",
        "  # Strip out punctuation\n",
        "  words=[]\n",
        "  for token in text:\n",
        "    if not token.is_punct:\n",
        "      words.append(token.text)\n",
        "  \n",
        "  # Build and return a `Counter` object containing word counts\n",
        "  return Counter(words)\n",
        "\n",
        "# Instantiate list of the most common words\n",
        "dialogs_word_freq = word_frequencies(dialogs_without_stopwords).most_common(10)\n",
        "print(dialogs_word_freq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('know', 21478), ('like', 13765), ('got', 12663), ('want', 10800), ('think', 10427), ('going', 8770), ('right', 8710), ('>', 7669), ('Oh', 7516), ('time', 6452)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYPatFNWG8dY"
      },
      "source": [
        "# lemmatization\n",
        "lemmas = [token.lemma_ for token in dialogs_without_stopwords]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shl_h4PXHEBp",
        "outputId": "cf1d940d-92db-4e17-da44-583eac9960c9"
      },
      "source": [
        "# Utility function to calculate how frequently each lemma appears in the text\n",
        "def lemma_frequencies(text):\n",
        "  # Build a list of lemmas\n",
        "  # Strip out punctuation\n",
        "  lemmas = []\n",
        "  for token in text:\n",
        "    if not token.is_punct:\n",
        "      lemmas.append(token.lemma_)\n",
        "    \n",
        "  # Build and return a `Counter` object containing word counts\n",
        "  return Counter(lemmas)\n",
        "\n",
        "# Instantiate your list of the most common words\n",
        "dialogs_lemma_freq = lemma_frequencies(dialogs_without_stopwords).most_common(10)\n",
        "\n",
        "print(dialogs_lemma_freq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('know', 24746), ('go', 16862), ('like', 15622), ('get', 15430), ('think', 15067), ('want', 13978), ('come', 10594), ('tell', 10492), ('right', 10108), ('look', 8811)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY4Noq5S7D7t"
      },
      "source": [
        "## Part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "YIXb_SYjJ8vE",
        "outputId": "26fe9d69-7729-4173-fca7-9e70c569afbd"
      },
      "source": [
        "postgres_user = 'dsbc_student'\n",
        "postgres_pw = '7*.8G9QH21'\n",
        "postgres_host = '142.93.121.174'\n",
        "postgres_port = '5432'\n",
        "postgres_db = 'twitter_sentiment'\n",
        "\n",
        "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
        "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
        "\n",
        "tweets_df = pd.read_sql_query('select * from twitter',con=engine)\n",
        "\n",
        "# no need for an open connection, as we're only doing a single query\n",
        "engine.dispose()\n",
        "\n",
        "\n",
        "tweets_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>570300767074181121</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>0.6842</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:14:33 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>570300616901320704</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.6745</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>cjmcginnis</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:13:57 -0800</td>\n",
              "      <td>San Francisco CA</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>570300248553349120</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6340</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>pilot</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:12:29 -0800</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>570299953286942721</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.6559</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>dhepburn</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@virginamerica Well, I didn'tâ€¦but NOW I DO! :-D</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:11:19 -0800</td>\n",
              "      <td>San Diego</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>570295459631263746</td>\n",
              "      <td>positive</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>YupitsTate</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 10:53:27 -0800</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index            tweet_id  ...    tweet_location               user_timezone\n",
              "0      0  570306133677760513  ...              None  Eastern Time (US & Canada)\n",
              "1      1  570301130888122368  ...              None  Pacific Time (US & Canada)\n",
              "2      2  570301083672813571  ...         Lets Play  Central Time (US & Canada)\n",
              "3      3  570301031407624196  ...              None  Pacific Time (US & Canada)\n",
              "4      4  570300817074462722  ...              None  Pacific Time (US & Canada)\n",
              "5      5  570300767074181121  ...              None  Pacific Time (US & Canada)\n",
              "6      6  570300616901320704  ...  San Francisco CA  Pacific Time (US & Canada)\n",
              "7      7  570300248553349120  ...       Los Angeles  Pacific Time (US & Canada)\n",
              "8      8  570299953286942721  ...         San Diego  Pacific Time (US & Canada)\n",
              "9      9  570295459631263746  ...       Los Angeles  Eastern Time (US & Canada)\n",
              "\n",
              "[10 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YT3oUisnEdM"
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "\n",
        "nlp.max_length = 20000000\n",
        "\n",
        "twitter_doc = nlp(\" \".join(tweets_df.text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgtG60KOnlU5",
        "outputId": "d4aa4c39-8386-456b-c83e-b87c9a94284c"
      },
      "source": [
        "# let's explore the objects we've built\n",
        "print(\"The twitter_doc object is a {} object\".format(type(twitter_doc)))\n",
        "print(\"It is {} tokens long\".format(len(twitter_doc)))\n",
        "print(\"The first three tokens are '{}'\".format(twitter_doc[:3]))\n",
        "print(\"The type of each token is {}\".format(type(twitter_doc[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The twitter_doc object is a <class 'spacy.tokens.doc.Doc'> object\n",
            "It is 307328 tokens long\n",
            "The first three tokens are '@VirginAmerica What @dhepburn'\n",
            "The type of each token is <class 'spacy.tokens.token.Token'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZHEikGjoMA6"
      },
      "source": [
        "# Removing the stopwords\n",
        "tweets_without_stopwords = [token for token in twitter_doc if not token.is_stop]\n",
        "\n",
        "tweets_word_freq = word_frequencies(tweets_without_stopwords).most_common(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj7tM4ecosCk",
        "outputId": "fd1f2e56-cef3-475a-d1b3-7335f4ad1a20"
      },
      "source": [
        "print(tweets_word_freq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('@united', 3733), ('flight', 3178), ('@AmericanAir', 2904), ('@USAirways', 2893), ('@SouthwestAir', 2390), ('@JetBlue', 2176), (' ', 1951), ('Cancelled', 1065), ('service', 928), ('time', 770)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQUzdl59oui4"
      },
      "source": [
        "# lemmatization\n",
        "tweet_lemmas = [token.lemma_ for token in tweets_without_stopwords]\n",
        "\n",
        "tweets_lemma_freq = lemma_frequencies(tweets_without_stopwords).most_common(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwldukEEpjia",
        "outputId": "131ae453-090a-4ff1-c590-c25b8b609cab"
      },
      "source": [
        "print(tweets_lemma_freq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('flight', 4006), ('@unite', 2712), ('@usairways', 2616), (' ', 1951), ('@JetBlue', 1740), ('thank', 1654), ('@AmericanAir', 1489), ('@americanair', 1450), ('@southwestair', 1280), ('@SouthwestAir', 1157)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}